{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ai/playground\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 전체 출력 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Output for model gpt-4o-mini ###\n",
      "\n",
      "{\n",
      "    \"개인화요소\": \"N\",\n",
      "    \"핵심 키워드\": [\"30분 독서\", \"최근 3개월 출간\", \"추운 날씨\"],\n",
      "    \"감정/분위기\": [\"따뜻한\", \"편안한\"],\n",
      "    \"시기/상황\": {\n",
      "        \"이전_이후\": \"이후\",\n",
      "        \"기준일\": \"2025-02-10\"\n",
      "    },\n",
      "    \"독서 목적\": [\"힐링\", \"가벼운 독서\"],\n",
      "    \"대상 독자\": \"NA\",\n",
      "    \"난이도\": 1,\n",
      "    \"분량\": {\n",
      "        \"최소_페이지\": 30,\n",
      "        \"최대_페이지\": 50\n",
      "    }\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "### Output for model gpt-4o ###\n",
      "\n",
      "{\n",
      "\"개인화요소\": \"N\",\n",
      "\"핵심 키워드\": [\"단시간 독서\", \"최근 출간\", \"추운 날씨\"],\n",
      "\"감정/분위기\": [\"따뜻한\", \"잔잔한\"],\n",
      "\"시기/상황\": {\n",
      "    \"이전_이후\": \"이후\",\n",
      "    \"기준일\": \"2024-11-10\"\n",
      "},\n",
      "\"독서 목적\": [\"힐링\", \"가벼운 독서\"],\n",
      "\"난이도\": 2,\n",
      "\"분량\": {\n",
      "    \"최소_페이지\": 50,\n",
      "    \"최대_페이지\": 100\n",
      "}\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "### Output for model o3-mini ###\n",
      "\n",
      "{\n",
      "  \"핵심 키워드\": [\"30분\", \"최근 3개월 이내 출판\", \"추운 날씨\"],\n",
      "  \"감정/분위기\": [\"따뜻한\"],\n",
      "  \"시기/상황\": {\n",
      "    \"이전_이후\": \"이후\",\n",
      "    \"기준일\": \"2025-02-10\"\n",
      "  },\n",
      "  \"독서 목적\": [\"간편 독서\"],\n",
      "  \"분량\": {\n",
      "    \"최소_페이지\": 50,\n",
      "    \"최대_페이지\": 120\n",
      "  }\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch the API key from the environment variable\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Define system prompt\n",
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": '''\n",
    "    <Basic>\n",
    "        1) 사용자 질문(Question)에 따라 핵심 정보를 추출하기 위해 키워드, 즉 슬롯을 추출하기 위한 프롬프트를 작성하고 싶어.\n",
    "        2) 다음과 같은 카테고리들을 \"슬롯\"이라고 명칭할 것이고 슬롯 목록은 다음과 같아: \"개인화요소\", \"핵심 키워드\", \"감정/분위기\", \"시기/상황\", \"독서 목적\", \"대상 독자\", \"난이도\", \"분량\"\n",
    "    </Basic>\n",
    "    <Check>\n",
    "        사용자 질문에서 핵심 정보를 추출하기 위해 다음 단계를 따를 것:\n",
    "        1) 질문의 핵심 주제나 의도를 파악하여 요청된 조건과 필요한 정보를 분리\n",
    "        2) 의미를 명확하게 전달하는 중요 단어를 선택하여 각 슬롯에 적합한 키워드를 추출\n",
    "            2-1. 질문에서 의미를 명확하게 전달하는 주요 명사, 형용사, 동사를 선택하여 적절한 슬롯에 매칭\n",
    "            2-2. 불필요한 연결어, 조사(은, 는, 이, 가 등) 및 일반적인 표현(예: 좋은 책)은 배제\n",
    "        3) 추출된 키워드는 각 슬롯 목록과 매칭되도록 구조화해서 정리(슬롯에 들어갈만한 쿼리값을 JSON형식으로 구조화하여 전달)\n",
    "            3-1. \"개인화요소\"는 메타정보와 매칭되는 경우 'Y', 아닌 경우는 'N'으로 출력하며 매칭되는 경우 해당 정보를 리스트 형식으로 제공\n",
    "            3-2. \"핵심 키워드\"\n",
    "            3-3. \"감정/분위기\"\n",
    "            3-4. \"시기/상황\"의 경우 오늘은 2025-02-10이며, 출간일 제한이 필요한 경우 yyyy-mm-dd 형태와 이전_이후 여부로 출력\n",
    "            3-5. \"독서 목적\"\n",
    "            3-6. \"대상 독자\"\n",
    "            3-7. \"난이도\"의 경우 1부터 5단계로 정의\n",
    "            3-8. \"분량\"의 경우 평균적인 일반단행본 페이지수를 고려하여 적절한 int값으로 제공(너무 짧은 분량이면 대상 도서가 없을 수도 있으니, 단편집 같은 적절한 포맷도 카테고리로 고려)\n",
    "\n",
    "        4) 3-1부터 3-8까지 매칭되지 않는 필드는 일단 NA로 반환한 후 <Notes> 조건을 반영해줘\n",
    "    </Check>\n",
    "    <Notes>\n",
    "        1) 매칭되지 않는 필드, 즉 \"NA\"로 반환되는 슬롯 값의 경우 값 또는 키값 모두 출력되지 않을 것\n",
    "        2) 날짜 포맷과 난이도 레벨, 페이지 수는 반드시 명시된 기준에 맞출 것\n",
    "        3) JSON은 참고할 부분을 키 값으로 해서 하나로 출력할 것\n",
    "    </Notes>\n",
    "    <Output>\n",
    "        질문에 대한 슬롯 매핑의 예시는 다음과 같습니다:\n",
    "\n",
    "        {\n",
    "        \"개인화요소\": \"N\",\n",
    "        \"핵심 키워드\": [\"단시간 독서\", \"최근 출간\", \"추운 날씨\"],\n",
    "        \"감정/분위기\": [\"따뜻한\", \"잔잔한\"],\n",
    "        \"시기/상황\": {\n",
    "            \"이전_이후\": \"이후\",\n",
    "            \"기준일\": \"2024-11-07\"\n",
    "        },\n",
    "        \"독서 목적\": [\"힐링\", \"가벼운 독서\"],\n",
    "        \"대상 독자\": \"NA\",\n",
    "        \"난이도\": 2,\n",
    "        \"분량\": {\n",
    "            \"최소_페이지\": 50,\n",
    "            \"최대_페이지\": 120\n",
    "        }\n",
    "        }\n",
    "    '''\n",
    "}\n",
    "\n",
    "# Function to create messages for the OpenAI API\n",
    "def create_messages(user_messages):\n",
    "    return [system_prompt] + [{\"role\": \"user\", \"content\": msg} for msg in user_messages]\n",
    "\n",
    "# Test user input\n",
    "user_messages = ['30분만에 읽을 만한 책 중 최근 3개월 이내 출판된 책으로 요즘 같은 추운 날씨에 읽기 좋은 책 추천해줘.']\n",
    "\n",
    "# Define function to test with multiple models\n",
    "def test_models(models):\n",
    "    results = {}\n",
    "    for model_name in models:\n",
    "        # Set the model in the environment\n",
    "        os.environ['LLM_MODEL'] = model_name\n",
    "        \n",
    "        # Create OpenAI client with current model\n",
    "        client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "        \n",
    "        # Create OpenAI messages\n",
    "        current_messages = create_messages(user_messages)\n",
    "        \n",
    "        # Make API call\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=current_messages,\n",
    "            stream=False\n",
    "        )\n",
    "        \n",
    "        # Store the result\n",
    "        results[model_name] = response.choices[0].message.content\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Models to test\n",
    "models_to_test = ['gpt-4o-mini', 'gpt-4o', 'o3-mini']\n",
    "\n",
    "# Test and print results\n",
    "output_results = test_models(models_to_test)\n",
    "\n",
    "# Display results for each model\n",
    "for model, output in output_results.items():\n",
    "    print(f\"### Output for model {model} ###\\n\")\n",
    "    print(output)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
